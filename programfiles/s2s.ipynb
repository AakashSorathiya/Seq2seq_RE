{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchtext.vocab import GloVe\n",
    "import torchcrf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2S Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, glove_embeddings):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_embeddings, freeze=False)\n",
    "        self.encoder = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embedding(inputs)\n",
    "        out, hidden = self.encoder(embeds)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(self, hidden_dim, tagset_size) -> None:\n",
    "        super().__init__()\n",
    "        self.decoder = nn.LSTM(hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, tagset_size)\n",
    "    \n",
    "    def forward(self, decoder_inputs):\n",
    "        out, hidden = self.decoder(decoder_inputs)\n",
    "        emissions = self.fc(out)\n",
    "        return emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        attention_weights = torch.tanh(self.attention(input))\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        out = input * attention_weights\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, tagset_size, encoder, decoder, attention):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.attention = attention\n",
    "        self.crf = torchcrf.CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        out, _ = self.encoder(sentence)\n",
    "        out = self.attention(out)\n",
    "        emissions = self.decoder(out)\n",
    "        \n",
    "        return emissions\n",
    "    \n",
    "    def loss(self, emissions, tags, mask=None):\n",
    "        return -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "    \n",
    "    def decode(self, emissions, mask=None):\n",
    "        return self.crf.decode(emissions, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(reviews):\n",
    "    word_to_ix = {word: i+1 for i, word in enumerate(set([w for s in reviews for w in s]))}\n",
    "    word_to_ix['<PAD>']=0\n",
    "    word_to_ix['<UNK>']=len(word_to_ix)\n",
    "    tag_to_ix = {'<PAD>': 0, 'B': 1, 'I': 2, 'O': 3}\n",
    "    ix_to_tag = {ix: tag for tag, ix in tag_to_ix.items()}\n",
    "    return word_to_ix, tag_to_ix, ix_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(sentences, tags, word_to_ix, tag_to_ix, pad_idx=0):\n",
    "    max_len = max(len(s) for s in sentences)\n",
    "    \n",
    "    sentences_idx = [[word_to_ix[word] for word in sent] + [pad_idx] * (max_len - len(sent)) for sent in sentences]\n",
    "    tags_idx = [[tag_to_ix[tag] for tag in tag_seq] + [pad_idx] * (max_len - len(tag_seq)) for tag_seq in tags]\n",
    "    \n",
    "    sentences_tensor = torch.tensor(sentences_idx, dtype=torch.long)\n",
    "    tags_tensor = torch.tensor(tags_idx, dtype=torch.long)\n",
    "    \n",
    "    return TensorDataset(sentences_tensor, tags_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove(EMBEDDING_DIM, VOCAB_SIZE, word_to_ix):\n",
    "    glove = GloVe(name='6B', dim=EMBEDDING_DIM)\n",
    "    glove_embeddings = torch.zeros(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    for word, idx in word_to_ix.items():\n",
    "        if word in glove.stoi:\n",
    "            glove_embeddings[idx] = glove[word]\n",
    "        else:\n",
    "            glove_embeddings[idx] = torch.randn(EMBEDDING_DIM)\n",
    "    return glove_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings, TAGSET_SIZE, device):\n",
    "    encoder = BiLSTMEncoder(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings)\n",
    "    decoder = LSTMDecoder(HIDDEN_DIM, TAGSET_SIZE)\n",
    "    attention = SelfAttention(HIDDEN_DIM)\n",
    "    model = Seq2SeqModel(TAGSET_SIZE, encoder, decoder, attention)\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_optimizer(model, lr=0.001):\n",
    "    return optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sentences_batch, tags_batch in train_loader:\n",
    "        sentences_batch = sentences_batch.to(device)\n",
    "        tags_batch = tags_batch.to(device)\n",
    "        \n",
    "        mask = (sentences_batch != 0)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emissions = model(sentences_batch)\n",
    "\n",
    "        loss = model.loss(emissions, tags_batch, mask)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Train Loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for sentences_batch, tags_batch in val_loader:\n",
    "            sentences_batch = sentences_batch.to(device)\n",
    "            tags_batch = tags_batch.to(device)\n",
    "            mask = (sentences_batch != 0)\n",
    "            \n",
    "            emissions = model(sentences_batch)\n",
    "            loss = model.loss(emissions, tags_batch, mask)\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Epoch: {epoch}, Validation Loss: {total_loss / len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, ix_to_tag):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    masks = []\n",
    "    with torch.no_grad():\n",
    "        for sentences_batch, _ in test_loader:\n",
    "            sentences_batch = sentences_batch.to(device)\n",
    "            mask = (sentences_batch != 0)\n",
    "            \n",
    "            emissions = model(sentences_batch)\n",
    "            predictions = model.decode(emissions, mask=mask)\n",
    "            pred_tags = [[ix_to_tag[t] for t in seq] for seq in predictions]\n",
    "            # print(pred_tags)\n",
    "            all_predictions.extend(pred_tags)\n",
    "            masks.extend(mask)\n",
    "    \n",
    "    return all_predictions, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, true_tags, true_tokens):\n",
    "    \n",
    "    levels = 1\n",
    "    \n",
    "    def extract_entities(seq, sentence):\n",
    "\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "        \n",
    "        for i, tag in enumerate(seq):\n",
    "            if tag == 'B':\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                current_entity = [sentence[i]]\n",
    "            elif tag == 'I':\n",
    "                if current_entity is None:\n",
    "                    current_entity = [sentence[i]]\n",
    "                else:\n",
    "                    current_entity.append(sentence[i])\n",
    "            elif tag == 'O':\n",
    "                if current_entity:\n",
    "                    entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "        \n",
    "        if current_entity:\n",
    "            entities.append(current_entity)\n",
    "        \n",
    "        return entities\n",
    "    \n",
    "    def is_match(f1, f2, n):\n",
    "        f1=set(f1)\n",
    "        f2=set(f2)\n",
    "        \n",
    "        is_subset = f1.issubset(f2) or f2.issubset(f1)\n",
    "        length_diff = abs(len(f1) - len(f2))\n",
    "        \n",
    "        return is_subset and length_diff <= n\n",
    "\n",
    "\n",
    "    all_true_entites = []\n",
    "    all_pred_entites = []\n",
    "    \n",
    "    for pred_seq, true_seq, token_seq in zip(predictions, true_tags, true_tokens):\n",
    "        true_entities = extract_entities(true_seq, token_seq)\n",
    "        pred_entities = extract_entities(pred_seq, token_seq)\n",
    "\n",
    "        all_true_entites.append(true_entities)\n",
    "        all_pred_entites.append(pred_entities)\n",
    "\n",
    "    total_true = len(all_true_entites)\n",
    "    total_pred = len(all_pred_entites)\n",
    "    metrics = {}\n",
    "\n",
    "    for level in range(levels):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "\n",
    "        for true_entities, pred_entities in zip(all_true_entites, all_pred_entites):   \n",
    "            matched_true = set()\n",
    "            for pred_entity in pred_entities:\n",
    "                found_match = False\n",
    "                \n",
    "                for i, true_entity in enumerate(true_entities):\n",
    "                    if i not in matched_true and is_match(pred_entity, true_entity, level):\n",
    "                        tp += 1\n",
    "                        matched_true.add(i)\n",
    "                        found_match = True\n",
    "                        break\n",
    "                \n",
    "                if not found_match:\n",
    "                    fp += 1\n",
    "\n",
    "            fn += len(true_entities) - len(matched_true)\n",
    "    \n",
    "        print(level, tp, fp, fn)\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        level_name = ['exact', 'n-1', 'n-2'][level]\n",
    "        metrics.update({\n",
    "            f'{level_name}_precision': precision,\n",
    "            f'{level_name}_recall': recall,\n",
    "            f'{level_name}_f1': f1\n",
    "        })\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cross_domain_data(df, category_key, word_to_ix, tag_to_ix, BATCH_SIZE):\n",
    "    cross_domain_data = []\n",
    "    for category in df[category_key].value_counts().keys():\n",
    "        train_sentences = df[df[category_key]!=category]['clean_content'].to_list()\n",
    "        train_tags = df[df[category_key]!=category]['tags'].to_list()\n",
    "        test_sentences = df[df[category_key]==category]['clean_content'].to_list()\n",
    "        test_tags = df[df[category_key]==category]['tags'].to_list()\n",
    "\n",
    "        train_data = prepare_data(train_sentences, train_tags, word_to_ix, tag_to_ix)\n",
    "        test_data = prepare_data(test_sentences, test_tags, word_to_ix, tag_to_ix)\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "        cross_domain_data.append({'app_name_category': category, 'train_loader': train_loader, 'test_loader': test_loader, 'test_tags': test_tags, 'test_sentences': test_sentences})\n",
    "    return cross_domain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_domain_training_eval(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings, TAGSET_SIZE, cross_domain_data, ix_to_tag, epochs, device):\n",
    "    results=[]\n",
    "    \n",
    "    for data in cross_domain_data:\n",
    "        print(f'For app name/category: {data['app_name_category']}')\n",
    "        model = initialize_model(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings, TAGSET_SIZE, device)\n",
    "        optimizer = initialize_optimizer(model, lr=0.001)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            train_model(model, data['train_loader'], optimizer, i)\n",
    "        test_predictions, masks = test_model(model, data['test_loader'], ix_to_tag)\n",
    "        f1_scores = calculate_metrics(test_predictions, data['test_tags'], data['test_sentences'])\n",
    "        results.append({data['app_name_category']: f1_scores})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation on Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datafiles/dataset_1_preprocessed.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_content'] = dataset['clean_content'].apply(ast.literal_eval)\n",
    "dataset['tags'] = dataset['tags'].apply(ast.literal_eval)\n",
    "dataset = dataset[dataset['clean_content'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 512\n",
    "EMBEDDING_DIM = 300\n",
    "epochs=10\n",
    "def out_domain_re_bert_test():\n",
    "    reviews = dataset['clean_content'].to_list()\n",
    "    tags = dataset['tags'].to_list()\n",
    "    word_to_ix, tag_to_ix, ix_to_tag = transform_data(reviews)\n",
    "    VOCAB_SIZE = len(word_to_ix)\n",
    "    TAGSET_SIZE = len(tag_to_ix)\n",
    "    glove_embeddings = get_glove(EMBEDDING_DIM, VOCAB_SIZE, word_to_ix)\n",
    "    out_domain_data = prepare_cross_domain_data(dataset, 'App id', word_to_ix, tag_to_ix, BATCH_SIZE)\n",
    "    results = cross_domain_training_eval(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings, TAGSET_SIZE, out_domain_data, ix_to_tag, epochs, device)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dataset_1=[]\n",
    "for run in range(15):\n",
    "    run_results = out_domain_re_bert_test()\n",
    "    all_results_dataset_1.append({'run': run+1, 'results': run_results})\n",
    "# Average of all the results reported above for final evaluation on dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation on Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datafiles/dataset_2_preprocessed.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['clean_content'] = dataset['clean_content'].apply(ast.literal_eval)\n",
    "dataset['tags'] = dataset['tags'].apply(ast.literal_eval)\n",
    "dataset = dataset[dataset['clean_content'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "HIDDEN_DIM = 512\n",
    "EMBEDDING_DIM = 300\n",
    "epochs=1\n",
    "def out_domain_tfrex_test():\n",
    "    reviews = dataset['clean_content'].to_list()\n",
    "    tags = dataset['tags'].to_list()\n",
    "    word_to_ix, tag_to_ix, ix_to_tag = transform_data(reviews)\n",
    "    VOCAB_SIZE = len(word_to_ix)\n",
    "    TAGSET_SIZE = len(tag_to_ix)\n",
    "    glove_embeddings = get_glove(EMBEDDING_DIM, VOCAB_SIZE, word_to_ix)\n",
    "    out_domain_data = prepare_cross_domain_data(dataset, 'category', word_to_ix, tag_to_ix, BATCH_SIZE)\n",
    "    results = cross_domain_training_eval(EMBEDDING_DIM, HIDDEN_DIM, glove_embeddings, TAGSET_SIZE, out_domain_data, ix_to_tag, epochs, device)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_dataset_2=[]\n",
    "for run in range(15):\n",
    "    run_results = out_domain_tfrex_test()\n",
    "    all_results_dataset_2.append({'run': run+1, 'results': run_results})\n",
    "# Average of all the results reported above for final evaluation on dataset 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
